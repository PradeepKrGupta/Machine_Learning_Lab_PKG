{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>student</th>\n",
       "      <th>credit rating</th>\n",
       "      <th>buys_computer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=30</td>\n",
       "      <td>high</td>\n",
       "      <td>no</td>\n",
       "      <td>fair</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;=30</td>\n",
       "      <td>high</td>\n",
       "      <td>no</td>\n",
       "      <td>excellent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31 . . .40</td>\n",
       "      <td>high</td>\n",
       "      <td>no</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;40</td>\n",
       "      <td>medium</td>\n",
       "      <td>no</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt;40</td>\n",
       "      <td>low</td>\n",
       "      <td>yes</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&gt;40</td>\n",
       "      <td>low</td>\n",
       "      <td>yes</td>\n",
       "      <td>excellent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31 . . .40</td>\n",
       "      <td>low</td>\n",
       "      <td>yes</td>\n",
       "      <td>excellent</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;=30</td>\n",
       "      <td>medium</td>\n",
       "      <td>no</td>\n",
       "      <td>fair</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;=30</td>\n",
       "      <td>low</td>\n",
       "      <td>yes</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&gt;40</td>\n",
       "      <td>medium</td>\n",
       "      <td>yes</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;=30</td>\n",
       "      <td>medium</td>\n",
       "      <td>yes</td>\n",
       "      <td>excellent</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31 . . .40</td>\n",
       "      <td>medium</td>\n",
       "      <td>no</td>\n",
       "      <td>excellent</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31 . . .40</td>\n",
       "      <td>high</td>\n",
       "      <td>yes</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&gt;40</td>\n",
       "      <td>medium</td>\n",
       "      <td>no</td>\n",
       "      <td>excellent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  income student credit rating buys_computer\n",
       "0         <=30    high      no          fair            no\n",
       "1         <=30    high      no     excellent            no\n",
       "2   31 . . .40    high      no          fair           yes\n",
       "3          >40  medium      no          fair           yes\n",
       "4          >40     low     yes          fair           yes\n",
       "5          >40     low     yes     excellent            no\n",
       "6   31 . . .40     low     yes     excellent           yes\n",
       "7         <=30  medium      no          fair            no\n",
       "8         <=30     low     yes          fair           yes\n",
       "9          >40  medium     yes          fair           yes\n",
       "10        <=30  medium     yes     excellent           yes\n",
       "11  31 . . .40  medium      no     excellent           yes\n",
       "12  31 . . .40    high     yes          fair           yes\n",
       "13         >40  medium      no     excellent            no"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Installing the dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Book1.csv')\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probability for \"buys_computer = no\": 0.357\n",
      "Prior probability for \"buys_computer = yes\": 0.643\n"
     ]
    }
   ],
   "source": [
    "# A1. For the data provided below, calculate the prior probability for each class. \n",
    "\n",
    "# Data\n",
    "data = [\n",
    "    ['<=30', 'high', 'no', 'fair', 'no'],\n",
    "    ['<=30', 'high', 'no', 'excellent', 'no'],\n",
    "    ['31 . . .40', 'high', 'no', 'fair', 'yes'],\n",
    "    ['>40', 'medium', 'no', 'fair', 'yes'],\n",
    "    ['>40', 'low', 'yes', 'fair', 'yes'],\n",
    "    ['>40', 'low', 'yes', 'excellent', 'no'],\n",
    "    ['31 . . .40', 'low', 'yes', 'excellent', 'yes'],\n",
    "    ['<=30', 'medium', 'no', 'fair', 'no'],\n",
    "    ['<=30', 'low', 'yes', 'fair', 'yes'],\n",
    "    ['>40', 'medium', 'yes', 'fair', 'yes'],\n",
    "    ['<=30', 'medium', 'yes', 'excellent', 'yes'],\n",
    "    ['31 . . .40', 'medium', 'no', 'excellent', 'yes'],\n",
    "    ['31 . . .40', 'high', 'yes', 'fair', 'yes'],\n",
    "    ['>40', 'medium', 'no', 'excellent', 'no']\n",
    "]\n",
    "\n",
    "# Extract the \"buys_computer\" column\n",
    "buys_computer_column = [row[-1] for row in data]\n",
    "\n",
    "# Calculate the prior probabilities\n",
    "total_instances = len(buys_computer_column)\n",
    "buys_computer_no = buys_computer_column.count('no')\n",
    "buys_computer_yes = buys_computer_column.count('yes')\n",
    "\n",
    "# Calculate the prior probabilities\n",
    "prior_no = buys_computer_no / total_instances\n",
    "prior_yes = buys_computer_yes / total_instances\n",
    "\n",
    "# Print the results\n",
    "print(f'Prior probability for \"buys_computer = no\": {prior_no:.3f}')\n",
    "print(f'Prior probability for \"buys_computer = yes\": {prior_yes:.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-conditional densities for age:\n",
      "P(age | buys_computer = no):\n",
      "  P(age = <=30 | buys_computer = no): 0.6000\n",
      "  P(age = >40 | buys_computer = no): 0.4000\n",
      "\n",
      "P(age | buys_computer = yes):\n",
      "  P(age = 31 . . .40 | buys_computer = yes): 0.4444\n",
      "  P(age = >40 | buys_computer = yes): 0.3333\n",
      "  P(age = <=30 | buys_computer = yes): 0.2222\n",
      "\n",
      "Class-conditional densities for income:\n",
      "P(income | buys_computer = no):\n",
      "  P(income = high | buys_computer = no): 0.4000\n",
      "  P(income = medium | buys_computer = no): 0.4000\n",
      "  P(income = low | buys_computer = no): 0.2000\n",
      "\n",
      "P(income | buys_computer = yes):\n",
      "  P(income = medium | buys_computer = yes): 0.4444\n",
      "  P(income = low | buys_computer = yes): 0.3333\n",
      "  P(income = high | buys_computer = yes): 0.2222\n",
      "\n",
      "Class-conditional densities for student:\n",
      "P(student | buys_computer = no):\n",
      "  P(student = no | buys_computer = no): 0.8000\n",
      "  P(student = yes | buys_computer = no): 0.2000\n",
      "\n",
      "P(student | buys_computer = yes):\n",
      "  P(student = yes | buys_computer = yes): 0.6667\n",
      "  P(student = no | buys_computer = yes): 0.3333\n",
      "\n",
      "Class-conditional densities for credit rating:\n",
      "P(credit rating | buys_computer = no):\n",
      "  P(credit rating = excellent | buys_computer = no): 0.6000\n",
      "  P(credit rating = fair | buys_computer = no): 0.4000\n",
      "\n",
      "P(credit rating | buys_computer = yes):\n",
      "  P(credit rating = fair | buys_computer = yes): 0.6667\n",
      "  P(credit rating = excellent | buys_computer = yes): 0.3333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A2.Calculate the class conditional densities for various features & classes. Observe if any class \n",
    "# conditional density has zero values.\n",
    "\n",
    "\n",
    "# Function to calculate class-conditional probabilities\n",
    "def calculate_conditional_probs(feature, label, df):\n",
    "    conditional_probs = {}\n",
    "    classes = df[label].unique()\n",
    "\n",
    "    for c in classes:\n",
    "        class_data = df[df[label] == c]\n",
    "        conditional_probs[c] = class_data[feature].value_counts(normalize=True).to_dict()\n",
    "\n",
    "    return conditional_probs\n",
    "\n",
    "# Calculate class-conditional probabilities for each feature\n",
    "for feature in df.columns[:-1]:  # Exclude the target variable\n",
    "    conditional_probs = calculate_conditional_probs(feature, 'buys_computer', df)\n",
    "    \n",
    "    print(f\"Class-conditional densities for {feature}:\")\n",
    "    for label, probs in conditional_probs.items():\n",
    "        print(f\"P({feature} | buys_computer = {label}):\")\n",
    "        for value, prob in probs.items():\n",
    "            print(f\"  P({feature} = {value} | buys_computer = {label}): {prob:.4f}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 12.95\n",
      "P-value: 0.6764100579553458\n",
      "Significance level: 0.05\n",
      "Is the p-value less than alpha? No\n",
      "Fail to reject the null hypothesis. There is no significant evidence of an association between the features.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A3. Test for independence between the 4 given features.\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(index=df['age'], columns=[df['income'], df['student'], df['credit rating']])\n",
    "\n",
    "# Perform chi-square test\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "print(f\"Significance level: {alpha}\")\n",
    "print(f\"Is the p-value less than alpha? {'Yes' if p < alpha else 'No'}\")\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"Reject the null hypothesis. There is evidence of a significant association between the features.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant evidence of an association between the features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRADEEP\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PRADEEP\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PRADEEP\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# A4. Build a Naïve-Bayes (NB) classifier for the above given data. Below code for help.\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# model = GaussianNB()\n",
    "# model.fit(Tr_X,Tr_y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df.columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop('buys_computer', axis=1)\n",
    "y = df['buys_computer']\n",
    "Tr_X, Te_X, Tr_y, Te_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train the Naïve-Bayes classifier\n",
    "model = GaussianNB()\n",
    "model.fit(Tr_X, Tr_y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(Te_X)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Te_y, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Te_y, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A5. Build a NB classifier for your own project data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
      "1414  3.590822  213.702299  33431.671122     5.542364  308.380612   \n",
      "2092  7.744099  219.658722  30809.705704     6.790681  333.775777   \n",
      "1177  5.484151  196.791251  19378.359067     5.003731  295.591019   \n",
      "427   9.879071  208.905645  14673.670669     6.240248  366.817639   \n",
      "3104  8.631270  164.371169  14880.651798     7.278263  350.951581   \n",
      "1530  7.080795  194.761215  38119.185568     6.998158  333.289216   \n",
      "65    6.203978  212.306618  21815.074148     7.873992  333.775777   \n",
      "3220  6.170526  193.335517  16206.219671     7.123966  333.775777   \n",
      "1389  9.395842  162.157700   9225.770911     8.275035  333.775777   \n",
      "2158  7.904053  217.771631  23575.991430     7.493024  279.146683   \n",
      "2605  8.445219  228.522860  28966.569327     6.179855  333.775777   \n",
      "2629  5.720136  182.440160  13463.852419     8.253966  333.775777   \n",
      "297   7.080795  191.285218  21948.325362     5.626787  355.488766   \n",
      "1077  8.037430  148.415309  48410.471014     4.755880  268.211896   \n",
      "836   8.054886  200.943484  12642.065947     7.309822  334.442064   \n",
      "1079  6.744799  204.084318  20215.697517     6.125252  304.527937   \n",
      "950   6.930391  190.189388  25780.059077     6.259353  331.030251   \n",
      "2666  6.376950  170.227080  16079.361250     5.433802  331.856892   \n",
      "2000  7.442023  194.763871  34565.701690     8.493348  294.836218   \n",
      "1911  6.851443  197.339559  15349.142585     7.446412  333.775777   \n",
      "\n",
      "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
      "1414    465.630119       18.126924        50.081054   4.144781           0  \n",
      "2092    405.032247       12.758777        70.371824   5.104188           0  \n",
      "1177    348.399033       18.713876        76.414153   4.438858           1  \n",
      "427     442.337486       19.626022        66.816581   4.218831           0  \n",
      "3104    444.108112       16.857459        58.177867   3.640944           0  \n",
      "1530    436.927417       13.746598        60.490581   3.356978           1  \n",
      "65      362.108004       14.933013        63.873820   5.215689           0  \n",
      "3220    528.096091       20.532277        75.067706   3.652207           1  \n",
      "1389    451.524629       12.632707        80.249886   3.530498           0  \n",
      "2158    548.155383       10.329558        65.180543   3.137280           0  \n",
      "2605    361.705354       14.554220        60.612230   4.400706           0  \n",
      "2629    401.509481       13.361778        52.952904   3.513255           0  \n",
      "297     509.406822       16.691471        84.107738   4.109590           1  \n",
      "1077    392.901206       12.466610        66.396293   2.506238           1  \n",
      "836     446.748442       14.949080        71.202038   3.514098           0  \n",
      "1079    544.339317       12.014243        72.608076   4.868543           1  \n",
      "950     481.737559       14.049483        70.586360   3.699796           0  \n",
      "2666    311.772900       15.703707        54.013112   4.284387           0  \n",
      "2000    350.085116       18.962014        79.958321   2.894651           1  \n",
      "1911    373.549867       11.367275        79.155822   4.935557           1  \n",
      "Accuracy: 0.6310975609756098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.88      0.75       412\n",
      "           1       0.51      0.22      0.30       244\n",
      "\n",
      "    accuracy                           0.63       656\n",
      "   macro avg       0.58      0.55      0.53       656\n",
      "weighted avg       0.60      0.63      0.58       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# Our Temporary Dataset( which we are using for Assignment Report)\n",
    "df1 = pd.read_csv('./waterPotability_updated.csv')\n",
    "print(df1.sample(20))\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df1.drop('Potability', axis=1)\n",
    "y = df1['Potability']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Gaussian Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Train the classifier on the training set\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Print the accuracy of the classifier\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# You can also print other metrics like precision, recall, and F1 score if needed\n",
    "print(metrics.classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6073245167853509\n",
      "Precision: 0.5103092783505154\n",
      "Recall: 0.5025380710659898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67       589\n",
      "           1       0.51      0.50      0.51       394\n",
      "\n",
      "    accuracy                           0.61       983\n",
      "   macro avg       0.59      0.59      0.59       983\n",
      "weighted avg       0.61      0.61      0.61       983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>Other Classifier We are using for the temporary Dataset<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "# 2.Decision Tree\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "X = df1.drop('Potability', axis=1)  # Features\n",
    "y = df1['Potability']  # Target variable\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)  # 70% training and 30% testing\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "# Classification report for a more detailed performance analysis\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6541200406917599\n",
      "Precision: 0.6243093922651933\n",
      "Recall: 0.2935064935064935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.89      0.76       598\n",
      "           1       0.62      0.29      0.40       385\n",
      "\n",
      "    accuracy                           0.65       983\n",
      "   macro avg       0.64      0.59      0.58       983\n",
      "weighted avg       0.65      0.65      0.62       983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.Random Forest\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "# Classification report for a more detailed performance analysis\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
